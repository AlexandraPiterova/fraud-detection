# ОПИСАНИЕ ЗАДАЧИ
---
Разработать ETL-процесс, получающий ежедневную выгрузку данных, загружающий ее в хранилище данных и строящий отчет.

### ВЫГРУЗКА ДАННЫХ
---
Ежедневно некие информационные системы выгружают следующие файлы: 
- Список транзакций за текущий день (в формате CSV); 
- Список терминалов полным срезом (в формате XLSX); 
- Список паспортов, включенных в «черный список» с накоплением с начала месяца (в формате XLSX). 

Сведения о картах, счетах и клиентах хранятся в СУБД PostgreSQL в схеме `BANK`. Предоставляется выгрузка за последние три дня, ее необходимо обработать.

### СТРУКТУРА ХРАНИЛИЩА
---
Данные должны быть загружены в хранилище со следующей структурой (имена сущностей указаны по существу, без особенностей правил нейминга, указанных далее):

![[storage_structure.png]]

Типы данных в полях можно изменять на однородные, если для этого есть необходимость. Имена полей менять нельзя. Ко всем таблицам SCD1 должны быть добавлены технические поля `create_dt`, `update_dt`; ко всем таблицам SCD2 должны быть добавлены технические поля `effective_from`, `effective_to`, `deleted_flg`.

### ПОСТРОЕНИЕ ОТЧЕТА
---
По результатам загрузки ежедневно необходимо строить витрину отчетности по мошенническим операциям. Витрина строится накоплением, каждый новый отчет укладывается в эту же таблицу с новым `report_dt`. 

В витрине должны содержаться следующие поля: 
- `event_dt` 
	Время наступления события. Если событие наступило по результату нескольких действий, указывается время действия, по которому установлен факт мошенничества. 
- `passport`
	Номер паспорта клиента, совершившего мошенническую операцию. 
- `fio` 
	ФИО клиента, совершившего мошенническую операцию. 
- `phone` 
	Номер телефона клиента, совершившего мошенническую операцию. 
- `event_type` 
	Описание типа мошенничества. 
- `report_dt` 
	Время построения отчета.

### ПРИЗНАКИ МОШЕННИЧЕСКИХ ОПЕРАЦИЙ
---
1. Совершение операции при просроченном или заблокированном паспорте. 
2. Совершение операции при недействующем договоре. 
3. Совершение операций в разных городах в течение одного часа. 
4. Попытка подбора суммы. В течение 20 минут проходит более трех операций со следующим шаблоном: каждая последующая меньше предыдущей, при этом отклонены все кроме последней. Последняя операция (успешная) в такой цепочке считается мошеннической.

### ПРАВИЛА ИМЕНОВАНИЯ ТАБЛИЦ
---
Необходимо придерживаться следующих правил именования: 
- `STG_<TABLE_NAME>`
	Таблицы для размещения стейджинговых таблиц (первоначальная загрузка), промежуточного выделения инкремента и временных таблиц, если требуется. Имя таблиц можно выбирать произвольное, но смысловое. 
- `DWH_FACT_<TABLE_NAME>`
	Таблицы фактов, загруженных в хранилище. В качестве фактов выступают сами транзакции и «черный список» паспортов. Имя таблиц – как в ER-диаграмме. 
- `DWH_DIM_<TABLE_NAME>`
	Таблицы измерений, хранящиеся в формате SCD1. Имя таблиц – как в ER-диаграмме. 
- `DWH_DIM_<TABLE_NAME>_HIST`
	Таблицы измерений, хранящиеся в формате SCD2. Имя таблиц – как в ER диаграмме. 
- `REP_FRAUD`
	Таблица с отчетом. 
- `META_<TABLE_NAME>`
	Таблицы для хранения метаданных. Имя таблиц можно выбирать произвольное, но смысловое. 

### ОБРАБОТКА ФАЙЛОВ
---
Выгружаемые файлы именуются согласно следующему шаблону:
- `transactions_DDMMYYYY.txt`
- `passport_blacklist_DDMMYYYY.xlsx`
- `terminals_DDMMYYYY.xlsx`

Предполагается, что в один день приходит по одному такому файлу. После загрузки соответствующего файла он должен быть переименован в файл с расширением `.backup` и перемещен в каталог `archive`:
- `transactions_DDMMYYYY.txt.backup`
- `passport_blacklist_DDMMYYYY.xlsx.backup`
- `terminals_DDMMYYYY.xlsx.backup`

# РЕШЕНИЕ
---
### КАК НАЧАТЬ РАБОТУ СО СТОРОНЫ PYTHON
---
**Необходимые составляющие для первоначального запуска проекта:**
- файл `main.py`
- папка `data` (для входящих файлов)
- папка `py_scripts`
- папка `sql_scripts`
- файл `db_config.json` (с параметрами подключения к БД) в формате:
```
	{
		"dbname": "",
		"user": "",
		"password": "",
		"host": "",
		"port": ""
	}
```
**Требования к библиотекам** перечислены в файле `requirements.txt`.

**Опционально:**
- папка `archive` (если ее нет, при необходимости она будет создана автоматически)
- папка `error` внутри папки `archive` (также будет создана автоматически при необходимости)
- файл `date_settings.json` в формате:
```
	{
		"is_active": "1",
		"start_dt": "2021-03-01 00:00:00",
		"end_dt": "2021-03-04 00:00:00"
	}
```

Файл `date_settings.json` используется для того, чтобы задать временной промежуток, за который нужно обновить отчет `REP_FRAUD`. Если файл `date_settings.json` отсутствует или параметр `"is_active" = 0`, информация в файле будет игнорироваться, и отчет по умолчанию будет обновлен на основе имеющихся данных о транзакциях за последние сутки. 

Например, если имеем данные о последней транзакции, произведенной `2021-03-03 23:45`, то временной промежуток будет по умолчанию задан как: `"start_dt": "2021-03-03 00:00:00"`, `"end_dt": "2021-03-04 00:00:00"`.

Если данные о транзакциях отсутствуют, сообщение об этом будет выведено в консоль.

Файлы, которые необходимо обработать, помещаются пользователем в папку `data`. Файлы будут обнаружены и обработаны автоматически, если их название соответствует установленному шаблону, а также в названии указана корректная дата:
- `transactions_DDMMYYYY.txt`
- `passport_blacklist_DDMMYYYY.xlsx`
- `terminals_DDMMYYYY.xlsx`

**Требования к дате в названии файла:**
- набор цифр должен являться настоящей датой (например, 30 февраля не будет являться подходящей датой);
- дата не должна находиться в будущем относительно настоящего момента времени;
- (для файла с данными о терминалах) дата должна быть новой относительно данных уже записанных в историческую таблицу. Если в таблице есть более свежие данные, файл не будет обработан.

**Пространство для доработки:** обновление исторических данных о терминалах за более ранние даты. Может потребоваться в случае, если, например, за какой-то промежуток времени данные не были обновлены, а после этого уже приходили более свежие данные.

### КАК НАЧАТЬ РАБОТУ СО СТОРОНЫ POSTGRESQL DATABASE
---
Никаких специальных действий кроме указания корректной информации в файле `db_config.json` не требуется.

Работа происходит в рамках схемы `BANK`. Если схема отсутствует, она будет создана автоматически. Также будут созданы все необходимые таблицы (если они отсутствуют).

Если таблицы `STG_CARDS`, `STG_ACCOUNTS`, `STG_CLIENTS` не созданы или пусты, они будут заполнены тестовыми данными из папки `sql_scripts`.

Для INSERT'а собственных тестовых данных необходимо заменить скрипты в папке `sql_scripts`.

### О ПРИНЦИПАХ РАБОТЫ ПРОГРАММЫ
---
Обработка данных происходит по следующему алгоритму:
1. Осуществляем подключение к БД на основе параметров из файла `db_config.json`.
	1. Если файл `db_config.json` не найден, будет выведена соответствующая ошибка.
	2. Если подключиться к БД не удалось, будет выведена соответствующая ошибка.
2. Функцией `recreate_test_data(connection, cursor, schema_name, replace=False)` создаем схему и все необходимые для начала работы таблицы, если они еще не созданы.
	1. Установить `replace=True`, если необходимо удалить всю схему и пересоздать все с нуля.
3. Функцией `update_from_files(...)` собираем информацию о кандидатах на обработку, лежащих в папке `data`, по следующему алгоритму:
	1. Функцией `find_files_to_process(...)` будет собрана информация о кандидатах на обработку, лежащих в той же директории, что и `main.py`.
		1. Информация о кандидатах будет помещена в таблицу `META_FILE_PROCESSING_LOG`. Если таблица отсутствует, она будет создана при первом выполнении программы.
		2. Если предыдущее выполнение программы было прервано и в таблице `META_FILE_PROCESSING_LOG` остались необработанные записи, им будет выставлена ошибка.
		3. Если дата в названии файла не соответствует требованиям, файл будет перемещен в папку `errors` и обрабатываться в дальнейшем не будет.
	2. Функцией `get_candidate_to_process(...)` из таблицы `META_FILE_PROCESSING_LOG` будут по очереди выбираться кандидаты для обработки, которым в п. 3.1 не была присвоена ошибка обработки.
		1. Отбор происходит по дате по возрастанию и далее по алфавиту.
	3. Если кандидат найден, информация из него будет помещена во временную таблицу `stg_tmp_loaded`. 
		1. Выбор метода чтения данных происходит на основе расширения файла.
	4. Функцией `update_dwh_table_from_tmp(...)` происходит обновление одной из рабочих таблиц из временной таблицы `stg_tmp_loaded` в зависимости от того, какие именно данные предоставлены в файле.
		1. Факт обработки файла фиксируется в таблице `META_FILE_PROCESSING_LOG`.
		2. Обработанный файл перемещается в папку `archive`.
	5. Если кандидатов больше нет, в консоль выводится сообщение о том, что обработка файлов завершена, а также сообщения об ошибках, если какие-то из файлов не были обработаны.
4. Начинается процесс поиска мошеннических операций за заданный промежуток времени. 
	1. Промежуток времени выбирается из файла `date_settings.json` или задается по умолчанию по алгоритму, описанному выше.
	2. Обнаруженные факты мошенничества фиксируются в таблице `DWH_DIM_FRAUD`, на основе которой строится отчет. Старые данные не удаляются, только дописываются новые.
	3. Полный отчет хранится в таблице `REP_FRAUD`. При запуске программы данные за заданный промежуток времени удаляются из `REP_FRAUD`, а затем записываются заново на основе `DWH_DIM_FRAUD`.

